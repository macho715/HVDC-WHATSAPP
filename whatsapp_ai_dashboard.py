"""
MACHO-GPT v3.4-mini WhatsApp AI Dashboard
HVDC Project - Samsung C&T Logistics
"""

import json
import streamlit as st
import pandas as pd
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
from collections import Counter

def load_ai_analysis(file_path: str):
    """Load AI analysis results"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        st.error(f"Failed to load analysis: {e}")
        return None

def create_keyword_chart(keywords: list):
    """Create keyword frequency chart"""
    if not keywords:
        return None
    
    # Count keyword frequency
    keyword_counts = Counter(keywords)
    
    # Create DataFrame
    df = pd.DataFrame(list(keyword_counts.items()), columns=['Keyword', 'Frequency'])
    df = df.sort_values('Frequency', ascending=True)
    
    # Create horizontal bar chart
    fig = px.bar(df, x='Frequency', y='Keyword', orientation='h',
                 title='ğŸ” í•µì‹¬ í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„',
                 color='Frequency',
                 color_continuous_scale='viridis')
    
    fig.update_layout(
        height=400,
        xaxis_title="ë¹ˆë„",
        yaxis_title="í‚¤ì›Œë“œ",
        showlegend=False
    )
    
    return fig

def create_sentiment_chart(analyses: list):
    """Create sentiment analysis chart"""
    sentiments = []
    for analysis in analyses:
        if 'analysis' in analysis and isinstance(analysis['analysis'], dict):
            sentiment = analysis['analysis'].get('sentiment', 'ì¤‘ë¦½')
            sentiments.append(sentiment)
    
    if not sentiments:
        return None
    
    # Count sentiments
    sentiment_counts = Counter(sentiments)
    
    # Create pie chart
    fig = px.pie(values=list(sentiment_counts.values()), 
                 names=list(sentiment_counts.keys()),
                 title='ğŸ“Š ê°ì • ë¶„ì„ ê²°ê³¼',
                 color_discrete_map={
                     'ê¸ì •': '#2E8B57',
                     'ë¶€ì •': '#DC143C', 
                     'ì¤‘ë¦½': '#4682B4'
                 })
    
    fig.update_layout(height=400)
    return fig

def create_message_count_chart(analyses: list):
    """Create message count chart"""
    chat_titles = []
    message_counts = []
    
    for analysis in analyses:
        chat_titles.append(analysis.get('chat_title', 'Unknown'))
        message_counts.append(analysis.get('message_count', 0))
    
    if not chat_titles:
        return None
    
    # Create bar chart
    fig = px.bar(x=chat_titles, y=message_counts,
                 title='ğŸ“± ì±„íŒ…ë°©ë³„ ë©”ì‹œì§€ ìˆ˜',
                 labels={'x': 'ì±„íŒ…ë°©', 'y': 'ë©”ì‹œì§€ ìˆ˜'},
                 color=message_counts,
                 color_continuous_scale='plasma')
    
    fig.update_layout(
        height=400,
        xaxis_tickangle=-45,
        showlegend=False
    )
    
    return fig

def create_issue_timeline_chart(analyses: list):
    """Create issue timeline chart"""
    issues = []
    for analysis in analyses:
        if 'analysis' in analysis and isinstance(analysis['analysis'], dict):
            issue = analysis['analysis'].get('issues', '')
            if issue and issue != 'ë¬¸ì œì  ì—†ìŒ':
                issues.append({
                    'chat': analysis.get('chat_title', 'Unknown'),
                    'issue': issue[:50] + '...' if len(issue) > 50 else issue
                })
    
    if not issues:
        return None
    
    # Create timeline chart
    fig = go.Figure()
    
    for i, issue_data in enumerate(issues):
        fig.add_trace(go.Scatter(
            x=[i],
            y=[issue_data['chat']],
            mode='markers+text',
            marker=dict(size=15, color='red'),
            text=issue_data['issue'],
            textposition='top center',
            name=issue_data['chat'],
            showlegend=False
        ))
    
    fig.update_layout(
        title='âš ï¸ ë¬¸ì œì  íƒ€ì„ë¼ì¸',
        height=300,
        xaxis=dict(showticklabels=False),
        yaxis=dict(title='ì±„íŒ…ë°©'),
        showlegend=False
    )
    
    return fig

def create_action_priority_chart(analyses: list):
    """Create action priority chart"""
    actions = []
    for analysis in analyses:
        if 'analysis' in analysis and isinstance(analysis['analysis'], dict):
            action = analysis['analysis'].get('actions', '')
            if action and action != 'ì¡°ì¹˜ì‚¬í•­ ì—†ìŒ':
                actions.append({
                    'chat': analysis.get('chat_title', 'Unknown'),
                    'action': action[:50] + '...' if len(action) > 50 else action
                })
    
    if not actions:
        return None
    
    # Create priority chart
    fig = go.Figure()
    
    for i, action_data in enumerate(actions):
        fig.add_trace(go.Scatter(
            x=[i],
            y=[action_data['chat']],
            mode='markers+text',
            marker=dict(size=15, color='green'),
            text=action_data['action'],
            textposition='top center',
            name=action_data['chat'],
            showlegend=False
        ))
    
    fig.update_layout(
        title='âœ… ì¡°ì¹˜ì‚¬í•­ ìš°ì„ ìˆœìœ„',
        height=300,
        xaxis=dict(showticklabels=False),
        yaxis=dict(title='ì±„íŒ…ë°©'),
        showlegend=False
    )
    
    return fig

def main():
    st.set_page_config(
        page_title="MACHO-GPT WhatsApp AI Dashboard",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    
    st.title("ğŸ¤– MACHO-GPT v3.4-mini WhatsApp AI ëŒ€ì‹œë³´ë“œ")
    st.subheader("HVDC Project - Samsung C&T Logistics")
    
    # Load latest analysis
    reports_dir = Path("reports")
    if not reports_dir.exists():
        st.error("ğŸ“ reports í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # Find latest analysis file
    analysis_files = list(reports_dir.glob("ai_analysis_*.json"))
    if not analysis_files:
        st.error("ğŸ“Š AI ë¶„ì„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    latest_file = max(analysis_files, key=lambda x: x.stat().st_mtime)
    st.info(f"ğŸ“„ ë¶„ì„ íŒŒì¼: {latest_file.name}")
    
    # Load analysis
    analysis = load_ai_analysis(latest_file)
    if not analysis:
        return
    
    # Display summary metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ì±„íŒ…ë°© ìˆ˜", analysis.get('total_chats_analyzed', 0))
    
    with col2:
        st.metric("ì´ ë©”ì‹œì§€", analysis.get('total_messages', 0))
    
    with col3:
        st.metric("í‚¤ì›Œë“œ ìˆ˜", analysis.get('overall_summary', {}).get('total_keywords', 0))
    
    with col4:
        timestamp = analysis.get('analysis_timestamp', '')
        if timestamp:
            dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
            st.metric("ë¶„ì„ ì‹œê°„", dt.strftime('%H:%M:%S'))
    
    st.divider()
    
    # Create charts - First row
    col1, col2 = st.columns(2)
    
    with col1:
        # Message count chart
        message_fig = create_message_count_chart(analysis.get('chat_analyses', []))
        if message_fig:
            st.plotly_chart(message_fig, use_container_width=True)
        
        # Sentiment chart
        sentiment_fig = create_sentiment_chart(analysis.get('chat_analyses', []))
        if sentiment_fig:
            st.plotly_chart(sentiment_fig, use_container_width=True)
    
    with col2:
        # Keyword chart
        keywords = analysis.get('overall_summary', {}).get('common_keywords', [])
        keyword_fig = create_keyword_chart(keywords)
        if keyword_fig:
            st.plotly_chart(keyword_fig, use_container_width=True)
    
    st.divider()
    
    # Create charts - Second row (Issues and Actions)
    col1, col2 = st.columns(2)
    
    with col1:
        # Issue timeline chart
        issue_fig = create_issue_timeline_chart(analysis.get('chat_analyses', []))
        if issue_fig:
            st.plotly_chart(issue_fig, use_container_width=True)
    
    with col2:
        # Action priority chart
        action_fig = create_action_priority_chart(analysis.get('chat_analyses', []))
        if action_fig:
            st.plotly_chart(action_fig, use_container_width=True)
    
    st.divider()
    
    # Display unique insights
    st.subheader("ğŸ¯ í•µì‹¬ ì¸ì‚¬ì´íŠ¸")
    
    # Extract unique insights from all analyses
    unique_insights = set()
    unique_issues = set()
    unique_actions = set()
    
    for chat_analysis in analysis.get('chat_analyses', []):
        if 'analysis' in chat_analysis and isinstance(chat_analysis['analysis'], dict):
            analysis_data = chat_analysis['analysis']
            
            # Collect unique insights
            summary = analysis_data.get('summary', '')
            if summary and summary != 'ìš”ì•½ ì—†ìŒ':
                unique_insights.add(summary[:100] + '...' if len(summary) > 100 else summary)
            
            # Collect unique issues
            issues = analysis_data.get('issues', '')
            if issues and issues != 'ë¬¸ì œì  ì—†ìŒ':
                unique_issues.add(issues[:100] + '...' if len(issues) > 100 else issues)
            
            # Collect unique actions
            actions = analysis_data.get('actions', '')
            if actions and actions != 'ì¡°ì¹˜ì‚¬í•­ ì—†ìŒ':
                unique_actions.add(actions[:100] + '...' if len(actions) > 100 else actions)
    
    # Display unique insights
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.write("**ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸:**")
        if unique_insights:
            for insight in list(unique_insights)[:3]:
                st.write(f"â€¢ {insight}")
        else:
            st.write("ì¸ì‚¬ì´íŠ¸ ì—†ìŒ")
    
    with col2:
        st.write("**âš ï¸ ì£¼ìš” ë¬¸ì œì :**")
        if unique_issues:
            for issue in list(unique_issues)[:3]:
                st.write(f"â€¢ {issue}")
        else:
            st.write("ë¬¸ì œì  ì—†ìŒ")
    
    with col3:
        st.write("**âœ… ì£¼ìš” ì¡°ì¹˜ì‚¬í•­:**")
        if unique_actions:
            for action in list(unique_actions)[:3]:
                st.write(f"â€¢ {action}")
        else:
            st.write("ì¡°ì¹˜ì‚¬í•­ ì—†ìŒ")
    
    st.divider()
    
    # Display chat-specific highlights
    st.subheader("ğŸ“± ì±„íŒ…ë°©ë³„ ì£¼ìš” íŠ¹ì§•")
    
    for chat_analysis in analysis.get('chat_analyses', []):
        chat_title = chat_analysis.get('chat_title', 'Unknown')
        message_count = chat_analysis.get('message_count', 0)
        
        with st.expander(f"ğŸ’¬ {chat_title} ({message_count}ê°œ ë©”ì‹œì§€)"):
            analysis_data = chat_analysis.get('analysis', {})
            
            # Show only unique or important information
            col1, col2 = st.columns(2)
            
            with col1:
                # Keywords
                keywords = analysis_data.get('keywords', [])
                if keywords:
                    st.write("**ğŸ·ï¸ ì£¼ìš” í‚¤ì›Œë“œ:**")
                    st.write(", ".join(keywords[:5]))  # Show only top 5
                
                # Schedule
                schedule = analysis_data.get('schedule', '')
                if schedule and schedule != 'ì¼ì • ì—†ìŒ':
                    st.write("**ğŸ“… ì£¼ìš” ì¼ì •:**")
                    st.write(schedule)
                
                # Progress
                progress = analysis_data.get('progress', '')
                if progress and progress != 'ì§„í–‰ í˜„í™© ì—†ìŒ':
                    st.write("**ğŸ”„ ì§„í–‰ í˜„í™©:**")
                    st.write(progress)
            
            with col2:
                # Sentiment with color coding
                sentiment = analysis_data.get('sentiment', 'ì¤‘ë¦½')
                st.write("**ğŸ˜Š ê°ì • ë¶„ì„:**")
                if sentiment == 'ê¸ì •':
                    st.success(sentiment)
                elif sentiment == 'ë¶€ì •':
                    st.error(sentiment)
                else:
                    st.info(sentiment)
                
                # Unique issues (if different from common ones)
                issues = analysis_data.get('issues', '')
                if issues and issues != 'ë¬¸ì œì  ì—†ìŒ':
                    st.write("**âš ï¸ íŠ¹ì´ì‚¬í•­:**")
                    st.write(issues)
                
                # Unique actions (if different from common ones)
                actions = analysis_data.get('actions', '')
                if actions and actions != 'ì¡°ì¹˜ì‚¬í•­ ì—†ìŒ':
                    st.write("**âœ… íŠ¹ë³„ ì¡°ì¹˜:**")
                    st.write(actions)
    
    # Overall summary
    st.divider()
    st.subheader("ğŸ¯ ì „ì²´ í”„ë¡œì íŠ¸ í˜„í™©")
    
    overall = analysis.get('overall_summary', {})
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ğŸ” í•µì‹¬ í‚¤ì›Œë“œ (ìƒìœ„ 10ê°œ):**")
        keywords = overall.get('common_keywords', [])
        if keywords:
            for i, keyword in enumerate(keywords[:10], 1):
                st.write(f"{i}. {keyword}")
        else:
            st.write("í‚¤ì›Œë“œ ì—†ìŒ")
    
    with col2:
        st.write("**âš ï¸ ì£¼ìš” ë¬¸ì œì :**")
        issues = overall.get('main_issues', [])
        if issues:
            for i, issue in enumerate(issues[:5], 1):  # Show only top 5
                st.write(f"{i}. {issue}")
        else:
            st.write("ë¬¸ì œì  ì—†ìŒ")
    
    st.write("**âœ… ìš°ì„  ì¡°ì¹˜ì‚¬í•­:**")
    actions = overall.get('required_actions', [])
    if actions:
        for i, action in enumerate(actions[:5], 1):  # Show only top 5
            st.write(f"{i}. {action}")
    else:
        st.write("ì¡°ì¹˜ì‚¬í•­ ì—†ìŒ")
    
    # Footer
    st.divider()
    st.caption("ğŸ¤– MACHO-GPT v3.4-mini | HVDC Project | Samsung C&T Logistics")

if __name__ == "__main__":
    main() 