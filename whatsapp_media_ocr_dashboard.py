#!/usr/bin/env python3
"""
WhatsApp ë¯¸ë””ì–´ OCR ë¶„ì„ ëŒ€ì‹œë³´ë“œ
--------------------------------
Streamlit ê¸°ë°˜ ë¯¸ë””ì–´ OCR ê²°ê³¼ ì‹œê°í™”

ê¸°ëŠ¥:
- ë¯¸ë””ì–´ OCR ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”
- íŒŒì¼ í˜•ì‹ë³„ í†µê³„
- OCR ì—”ì§„ë³„ ì„±ëŠ¥ ë¹„êµ
- í…ìŠ¤íŠ¸ ì¶”ì¶œ í’ˆì§ˆ ë¶„ì„
- ë¯¼ê° ì •ë³´ ê°ì§€ ë° ìµëª…í™” í˜„í™©
"""

import streamlit as st
import json
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
from datetime import datetime
from collections import Counter
import re

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="WhatsApp ë¯¸ë””ì–´ OCR ë¶„ì„ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“±",
    layout="wide",
    initial_sidebar_state="expanded"
)

def load_latest_media_ocr_result():
    """ìµœì‹  ë¯¸ë””ì–´ OCR ê²°ê³¼ íŒŒì¼ ë¡œë“œ"""
    data_dir = Path('data')
    if not data_dir.exists():
        return None
    
    # ë¯¸ë””ì–´ OCR ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
    media_files = list(data_dir.glob('whatsapp_media_ocr_*.json'))
    if not media_files:
        return None
    
    # ìµœì‹  íŒŒì¼ ì„ íƒ
    latest_file = max(media_files, key=lambda x: x.stat().st_mtime)
    
    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def create_file_type_chart(media_results):
    """íŒŒì¼ í˜•ì‹ë³„ ì°¨íŠ¸ ìƒì„±"""
    if not media_results:
        return None
    
    file_types = [media.get('file_type', 'unknown') for media in media_results]
    type_counts = Counter(file_types)
    
    fig = px.pie(
        values=list(type_counts.values()),
        names=list(type_counts.keys()),
        title="ğŸ“ íŒŒì¼ í˜•ì‹ë³„ ë¶„í¬",
        color_discrete_sequence=px.colors.qualitative.Set3
    )
    fig.update_traces(textposition='inside', textinfo='percent+label')
    
    return fig

def create_ocr_engine_chart(media_results):
    """OCR ì—”ì§„ë³„ ì„±ëŠ¥ ì°¨íŠ¸ ìƒì„±"""
    if not media_results:
        return None
    
    engine_data = []
    for media in media_results:
        ocr_result = media.get('ocr_result', {})
        engine = ocr_result.get('engine', 'unknown')
        confidence = ocr_result.get('confidence', 0)
        if confidence > 0:
            engine_data.append({
                'engine': engine,
                'confidence': confidence,
                'file_type': media.get('file_type', 'unknown')
            })
    
    if not engine_data:
        return None
    
    df = pd.DataFrame(engine_data)
    
    fig = px.box(
        df, 
        x='engine', 
        y='confidence',
        color='file_type',
        title="ğŸ” OCR ì—”ì§„ë³„ ì‹ ë¢°ë„ ë¶„í¬",
        labels={'confidence': 'ì‹ ë¢°ë„', 'engine': 'OCR ì—”ì§„'}
    )
    
    return fig

def create_confidence_distribution_chart(media_results):
    """ì‹ ë¢°ë„ ë¶„í¬ ì°¨íŠ¸ ìƒì„±"""
    if not media_results:
        return None
    
    confidences = []
    for media in media_results:
        ocr_result = media.get('ocr_result', {})
        confidence = ocr_result.get('confidence', 0)
        if confidence > 0:
            confidences.append(confidence)
    
    if not confidences:
        return None
    
    fig = px.histogram(
        x=confidences,
        nbins=20,
        title="ğŸ“Š OCR ì‹ ë¢°ë„ ë¶„í¬",
        labels={'x': 'ì‹ ë¢°ë„', 'y': 'íŒŒì¼ ìˆ˜'},
        color_discrete_sequence=['#636EFA']
    )
    
    # í‰ê· ì„  ì¶”ê°€
    mean_confidence = sum(confidences) / len(confidences)
    fig.add_vline(x=mean_confidence, line_dash="dash", line_color="red",
                  annotation_text=f"í‰ê· : {mean_confidence:.2f}")
    
    return fig

def create_text_length_chart(media_results):
    """í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„í¬ ì°¨íŠ¸ ìƒì„±"""
    if not media_results:
        return None
    
    text_lengths = []
    for media in media_results:
        ocr_result = media.get('ocr_result', {})
        text = ocr_result.get('text', '')
        if text.strip():
            text_lengths.append(len(text))
    
    if not text_lengths:
        return None
    
    fig = px.histogram(
        x=text_lengths,
        nbins=15,
        title="ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„í¬",
        labels={'x': 'í…ìŠ¤íŠ¸ ê¸¸ì´ (ë¬¸ì)', 'y': 'íŒŒì¼ ìˆ˜'},
        color_discrete_sequence=['#00CC96']
    )
    
    return fig

def analyze_sensitive_info(media_results):
    """ë¯¼ê° ì •ë³´ ë¶„ì„"""
    sensitive_patterns = {
        'ì „í™”ë²ˆí˜¸': r'\b\d{3}-\d{3}-\d{4}\b',
        'ì£¼ë¯¼ë²ˆí˜¸': r'\b\d{6}-\d{7}\b',
        'ì—¬ê¶Œë²ˆí˜¸': r'\b[A-Z0-9]{9}\b',
        'ì‹ ìš©ì¹´ë“œ': r'\b\d{4}-\d{4}-\d{4}-\d{4}\b',
        'ì´ë©”ì¼': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    }
    
    sensitive_counts = Counter()
    total_files = 0
    
    for media in media_results:
        ocr_result = media.get('ocr_result', {})
        text = ocr_result.get('text', '')
        if text.strip():
            total_files += 1
            for pattern_name, pattern in sensitive_patterns.items():
                if re.search(pattern, text):
                    sensitive_counts[pattern_name] += 1
    
    return sensitive_counts, total_files

def create_processing_timeline(media_results):
    """ì²˜ë¦¬ ì‹œê°„ íƒ€ì„ë¼ì¸ ì°¨íŠ¸ ìƒì„±"""
    if not media_results:
        return None
    
    timeline_data = []
    for media in media_results:
        processed_at = media.get('processed_at', '')
        if processed_at:
            try:
                dt = datetime.fromisoformat(processed_at.replace('Z', '+00:00'))
                timeline_data.append({
                    'time': dt,
                    'file_name': media.get('file_name', 'Unknown'),
                    'file_type': media.get('file_type', 'unknown'),
                    'confidence': media.get('ocr_result', {}).get('confidence', 0)
                })
            except:
                continue
    
    if not timeline_data:
        return None
    
    df = pd.DataFrame(timeline_data)
    df = df.sort_values('time')
    
    fig = px.scatter(
        df,
        x='time',
        y='confidence',
        color='file_type',
        size='confidence',
        hover_data=['file_name'],
        title="â° ì²˜ë¦¬ ì‹œê°„ë³„ OCR ì‹ ë¢°ë„",
        labels={'time': 'ì²˜ë¦¬ ì‹œê°„', 'confidence': 'ì‹ ë¢°ë„'}
    )
    
    return fig

def main():
    st.title("ğŸ“± WhatsApp ë¯¸ë””ì–´ OCR ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°” - íŒŒì¼ ì„ íƒ
    st.sidebar.header("ğŸ“‚ ë°ì´í„° ì„ íƒ")
    
    # ìµœì‹  ê²°ê³¼ ìë™ ë¡œë“œ
    result_data = load_latest_media_ocr_result()
    
    if result_data is None:
        st.warning("âš ï¸ ë¯¸ë””ì–´ OCR ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.info("ğŸ’¡ `python whatsapp_media_ocr_extractor.py` ëª…ë ¹ìœ¼ë¡œ ë¯¸ë””ì–´ ì¶”ì¶œì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    # ê²°ê³¼ ë°ì´í„° êµ¬ì¡° í™•ì¸
    if 'chat_results' in result_data:
        # ì „ì²´ ê²°ê³¼ (ì—¬ëŸ¬ ì±„íŒ…ë°©)
        chat_results = result_data['chat_results']
        st.sidebar.success(f"ğŸ“Š ì „ì²´ ê²°ê³¼ ë¡œë“œë¨ ({len(chat_results)}ê°œ ì±„íŒ…ë°©)")
        
        # ì±„íŒ…ë°© ì„ íƒ
        selected_chat = st.sidebar.selectbox(
            "ì±„íŒ…ë°© ì„ íƒ",
            [chat['chat_title'] for chat in chat_results],
            index=0
        )
        
        # ì„ íƒëœ ì±„íŒ…ë°©ì˜ ê²°ê³¼
        selected_result = next(
            (chat for chat in chat_results if chat['chat_title'] == selected_chat),
            None
        )
        
        if selected_result:
            media_results = selected_result.get('media_results', [])
        else:
            media_results = []
    else:
        # ë‹¨ì¼ ì±„íŒ…ë°© ê²°ê³¼
        media_results = result_data.get('media_results', [])
        st.sidebar.success(f"ğŸ“Š ë‹¨ì¼ ì±„íŒ…ë°© ê²°ê³¼ ë¡œë“œë¨")
    
    # ë©”ì¸ ëŒ€ì‹œë³´ë“œ
    if not media_results:
        st.warning("âš ï¸ ì²˜ë¦¬ëœ ë¯¸ë””ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ìƒë‹¨ í†µê³„ ì¹´ë“œ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ“ ì´ ë¯¸ë””ì–´", len(media_results))
    
    with col2:
        processed_count = sum(1 for m in media_results if 'ocr_result' in m)
        st.metric("âœ… ì²˜ë¦¬ ì™„ë£Œ", processed_count)
    
    with col3:
        avg_confidence = 0
        confidences = [m.get('ocr_result', {}).get('confidence', 0) for m in media_results]
        if confidences:
            avg_confidence = sum(confidences) / len(confidences)
        st.metric("ğŸ¯ í‰ê·  ì‹ ë¢°ë„", f"{avg_confidence:.2f}")
    
    with col4:
        text_extracted = sum(1 for m in media_results if m.get('ocr_result', {}).get('text', '').strip())
        st.metric("ğŸ“ í…ìŠ¤íŠ¸ ì¶”ì¶œ", text_extracted)
    
    st.markdown("---")
    
    # ì°¨íŠ¸ ì„¹ì…˜
    col1, col2 = st.columns(2)
    
    with col1:
        # íŒŒì¼ í˜•ì‹ë³„ ì°¨íŠ¸
        file_type_fig = create_file_type_chart(media_results)
        if file_type_fig:
            st.plotly_chart(file_type_fig, use_container_width=True)
        
        # OCR ì—”ì§„ë³„ ì„±ëŠ¥ ì°¨íŠ¸
        engine_fig = create_ocr_engine_chart(media_results)
        if engine_fig:
            st.plotly_chart(engine_fig, use_container_width=True)
    
    with col2:
        # ì‹ ë¢°ë„ ë¶„í¬ ì°¨íŠ¸
        confidence_fig = create_confidence_distribution_chart(media_results)
        if confidence_fig:
            st.plotly_chart(confidence_fig, use_container_width=True)
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„í¬ ì°¨íŠ¸
        text_length_fig = create_text_length_chart(media_results)
        if text_length_fig:
            st.plotly_chart(text_length_fig, use_container_width=True)
    
    # ì²˜ë¦¬ ì‹œê°„ íƒ€ì„ë¼ì¸
    timeline_fig = create_processing_timeline(media_results)
    if timeline_fig:
        st.plotly_chart(timeline_fig, use_container_width=True)
    
    # ë¯¼ê° ì •ë³´ ë¶„ì„
    st.markdown("---")
    st.subheader("ğŸ”’ ë¯¼ê° ì •ë³´ ë¶„ì„")
    
    sensitive_counts, total_files = analyze_sensitive_info(media_results)
    
    if sensitive_counts:
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ê°ì§€ëœ ë¯¼ê° ì •ë³´:**")
            for info_type, count in sensitive_counts.items():
                st.write(f"â€¢ {info_type}: {count}ê°œ íŒŒì¼")
        
        with col2:
            st.write("**ìµëª…í™” í˜„í™©:**")
            st.success(f"âœ… ëª¨ë“  ë¯¼ê° ì •ë³´ê°€ ìë™ ìµëª…í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.info(f"ğŸ“Š ì´ {total_files}ê°œ íŒŒì¼ ì¤‘ {sum(sensitive_counts.values())}ê°œì—ì„œ ë¯¼ê° ì •ë³´ ê°ì§€")
    else:
        st.success("âœ… ë¯¼ê° ì •ë³´ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # ìƒì„¸ ê²°ê³¼ í…Œì´ë¸”
    st.markdown("---")
    st.subheader("ğŸ“‹ ìƒì„¸ ì²˜ë¦¬ ê²°ê³¼")
    
    # í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
    table_data = []
    for media in media_results:
        ocr_result = media.get('ocr_result', {})
        table_data.append({
            'íŒŒì¼ëª…': media.get('file_name', 'Unknown'),
            'í˜•ì‹': media.get('file_type', 'unknown'),
            'í¬ê¸° (KB)': round(media.get('file_size', 0) / 1024, 1),
            'OCR ì—”ì§„': ocr_result.get('engine', 'N/A'),
            'ì‹ ë¢°ë„': f"{ocr_result.get('confidence', 0):.2f}",
            'í…ìŠ¤íŠ¸ ê¸¸ì´': len(ocr_result.get('text', '')),
            'ì²˜ë¦¬ ì‹œê°„': media.get('processed_at', 'N/A')[:19] if media.get('processed_at') else 'N/A'
        })
    
    df = pd.DataFrame(table_data)
    st.dataframe(df, use_container_width=True)
    
    # í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
    st.markdown("---")
    st.subheader("ğŸ“„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¯¸ë¦¬ë³´ê¸°")
    
    for i, media in enumerate(media_results[:5]):  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
        ocr_result = media.get('ocr_result', {})
        text = ocr_result.get('text', '')
        
        if text.strip():
            with st.expander(f"ğŸ“„ {media.get('file_name', 'Unknown')} (ì‹ ë¢°ë„: {ocr_result.get('confidence', 0):.2f})"):
                st.text_area(
                    "ì¶”ì¶œëœ í…ìŠ¤íŠ¸:",
                    text,
                    height=150,
                    key=f"text_{i}",
                    disabled=True
                )
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: #666;'>
        ğŸ¤– MACHO-GPT v3.4-mini | Samsung C&T Logistics Â· HVDC Project<br>
        ğŸ“± WhatsApp ë¯¸ë””ì–´ OCR ë¶„ì„ ëŒ€ì‹œë³´ë“œ
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main() 