#!/usr/bin/env python3
"""
WhatsApp ë¯¸ë””ì–´ OCR ë¶„ì„ ëŒ€ì‹œë³´ë“œ (ì—…ê·¸ë ˆì´ë“œ)
-----------------------------------------------
Streamlit ê¸°ë°˜ ë¯¸ë””ì–´ OCR ê²°ê³¼ ì‹œê°í™”
- ë‹¤ì¤‘ OCR ì—”ì§„ ì„±ëŠ¥ ë¹„êµ
- íŒŒì¼ í˜•ì‹ë³„ ì²˜ë¦¬ í†µê³„
- ì‹ ë¢°ë„ ë¶„í¬ ë¶„ì„
- ì²˜ë¦¬ ì‹œê°„ ì¶”ì´
- ì—”ì§„ë³„ ì •í™•ë„ ë¹„êµ
"""

import streamlit as st
import json
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
from datetime import datetime
from collections import Counter
import re
import numpy as np

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="WhatsApp ë¯¸ë””ì–´ OCR ë¶„ì„ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“±",
    layout="wide",
    initial_sidebar_state="expanded"
)

def load_latest_results():
    """ìµœì‹  OCR ê²°ê³¼ íŒŒì¼ ë¡œë“œ"""
    data_dir = Path("data")
    if not data_dir.exists():
        return None
        
    # JSON íŒŒì¼ ì°¾ê¸°
    json_files = list(data_dir.glob("whatsapp_media_ocr_*.json"))
    if not json_files:
        return None
        
    # ìµœì‹  íŒŒì¼ ì„ íƒ
    latest_file = max(json_files, key=lambda x: x.stat().st_mtime)
    
    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data, latest_file.name
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None, None

def create_engine_comparison_chart(data):
    """OCR ì—”ì§„ ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸"""
    if not data or 'media_results' not in data:
        return None
        
    engine_stats = {}
    
    for result in data['media_results']:
        ocr_result = result.get('ocr_result', {})
        engine = ocr_result.get('engine', 'unknown')
        confidence = ocr_result.get('confidence', 0)
        
        if engine not in engine_stats:
            engine_stats[engine] = {
                'count': 0,
                'total_confidence': 0,
                'success_count': 0
            }
            
        engine_stats[engine]['count'] += 1
        engine_stats[engine]['total_confidence'] += confidence
        
        if confidence > 0:
            engine_stats[engine]['success_count'] += 1
    
    # DataFrame ìƒì„±
    df = pd.DataFrame([
        {
            'engine': engine,
            'total_files': stats['count'],
            'avg_confidence': stats['total_confidence'] / stats['count'] if stats['count'] > 0 else 0,
            'success_rate': stats['success_count'] / stats['count'] if stats['count'] > 0 else 0
        }
        for engine, stats in engine_stats.items()
    ])
    
    if df.empty:
        return None
        
    # ì°¨íŠ¸ ìƒì„±
    fig = go.Figure()
    
    # í‰ê·  ì‹ ë¢°ë„
    fig.add_trace(go.Bar(
        x=df['engine'],
        y=df['avg_confidence'],
        name='í‰ê·  ì‹ ë¢°ë„',
        marker_color='lightblue',
        yaxis='y'
    ))
    
    # ì„±ê³µë¥ 
    fig.add_trace(go.Scatter(
        x=df['engine'],
        y=df['success_rate'],
        name='ì„±ê³µë¥ ',
        mode='lines+markers',
        line=dict(color='red', width=3),
        yaxis='y2'
    ))
    
    fig.update_layout(
        title="OCR ì—”ì§„ ì„±ëŠ¥ ë¹„êµ",
        xaxis_title="OCR ì—”ì§„",
        yaxis=dict(title="í‰ê·  ì‹ ë¢°ë„", side="left"),
        yaxis2=dict(title="ì„±ê³µë¥ ", side="right", overlaying="y"),
        barmode='group',
        height=400
    )
    
    return fig

def create_file_type_distribution(data):
    """íŒŒì¼ í˜•ì‹ ë¶„í¬ ì°¨íŠ¸"""
    if not data or 'media_results' not in data:
        return None
        
    file_types = []
    for result in data['media_results']:
        media_info = result.get('media_info', {})
        file_type = media_info.get('type', 'unknown')
        file_types.append(file_type)
    
    if not file_types:
        return None
        
    # íŒŒì¼ í˜•ì‹ ì¹´ìš´íŠ¸
    type_counts = Counter(file_types)
    
    fig = px.pie(
        values=list(type_counts.values()),
        names=list(type_counts.keys()),
        title="íŒŒì¼ í˜•ì‹ ë¶„í¬",
        color_discrete_sequence=px.colors.qualitative.Set3
    )
    
    fig.update_traces(textposition='inside', textinfo='percent+label')
    return fig

def create_confidence_distribution(data):
    """ì‹ ë¢°ë„ ë¶„í¬ ì°¨íŠ¸"""
    if not data or 'media_results' not in data:
        return None
        
    confidences = []
    engines = []
    
    for result in data['media_results']:
        ocr_result = result.get('ocr_result', {})
        confidence = ocr_result.get('confidence', 0)
        engine = ocr_result.get('engine', 'unknown')
        
        if confidence > 0:
            confidences.append(confidence)
            engines.append(engine)
    
    if not confidences:
        return None
        
    df = pd.DataFrame({
        'confidence': confidences,
        'engine': engines
    })
    
    fig = px.histogram(
        df,
        x='confidence',
        color='engine',
        title="OCR ì‹ ë¢°ë„ ë¶„í¬",
        nbins=20,
        opacity=0.7
    )
    
    fig.update_layout(
        xaxis_title="ì‹ ë¢°ë„",
        yaxis_title="íŒŒì¼ ìˆ˜",
        height=400
    )
    
    return fig

def create_processing_timeline(data):
    """ì²˜ë¦¬ ì‹œê°„ ì¶”ì´ ì°¨íŠ¸"""
    if not data or 'media_results' not in data:
        return None
        
    timestamps = []
    engines = []
    confidences = []
    
    for result in data['media_results']:
        processed_at = result.get('processed_at')
        ocr_result = result.get('ocr_result', {})
        
        if processed_at:
            try:
                timestamp = datetime.fromisoformat(processed_at.replace('Z', '+00:00'))
                timestamps.append(timestamp)
                engines.append(ocr_result.get('engine', 'unknown'))
                confidences.append(ocr_result.get('confidence', 0))
            except:
                continue
    
    if not timestamps:
        return None
        
    df = pd.DataFrame({
        'timestamp': timestamps,
        'engine': engines,
        'confidence': confidences
    })
    
    fig = px.scatter(
        df,
        x='timestamp',
        y='confidence',
        color='engine',
        title="ì²˜ë¦¬ ì‹œê°„ë³„ OCR ì„±ëŠ¥",
        size='confidence',
        hover_data=['engine']
    )
    
    fig.update_layout(
        xaxis_title="ì²˜ë¦¬ ì‹œê°„",
        yaxis_title="ì‹ ë¢°ë„",
        height=400
    )
    
    return fig

def analyze_sensitive_info(data):
    """ë¯¼ê° ì •ë³´ ë¶„ì„"""
    if not data or 'media_results' not in data:
        return None
        
    sensitive_patterns = {
        'phone': r'\[PHONE\]',
        'email': r'\[EMAIL\]',
        'id_number': r'\[ID_NUMBER\]',
        'card_number': r'\[CARD_NUMBER\]'
    }
    
    sensitive_counts = {k: 0 for k in sensitive_patterns.keys()}
    total_texts = 0
    
    for result in data['media_results']:
        ocr_result = result.get('ocr_result', {})
        text = ocr_result.get('text', '')
        
        if text:
            total_texts += 1
            for pattern_name, pattern in sensitive_patterns.items():
                if re.search(pattern, text):
                    sensitive_counts[pattern_name] += 1
    
    return sensitive_counts, total_texts

def create_performance_metrics(data):
    """ì„±ëŠ¥ ì§€í‘œ ì¹´ë“œ"""
    if not data:
        return None
        
    metrics = {}
    
    # ê¸°ë³¸ í†µê³„
    metrics['total_media'] = data.get('media_count', 0)
    metrics['processed_media'] = data.get('processed_count', 0)
    metrics['success_rate'] = (metrics['processed_media'] / metrics['total_media'] * 100) if metrics['total_media'] > 0 else 0
    
    # OCR ì—”ì§„ í†µê³„
    if 'media_results' in data:
        engines = [r.get('ocr_result', {}).get('engine', 'unknown') for r in data['media_results']]
        engine_counts = Counter(engines)
        metrics['engines_used'] = len(engine_counts)
        metrics['most_used_engine'] = engine_counts.most_common(1)[0][0] if engine_counts else 'N/A'
        
        # í‰ê·  ì‹ ë¢°ë„
        confidences = [r.get('ocr_result', {}).get('confidence', 0) for r in data['media_results']]
        confidences = [c for c in confidences if c > 0]
        metrics['avg_confidence'] = np.mean(confidences) if confidences else 0
    
    return metrics

def main():
    st.title("ğŸ“± WhatsApp ë¯¸ë””ì–´ OCR ë¶„ì„ ëŒ€ì‹œë³´ë“œ (ì—…ê·¸ë ˆì´ë“œ)")
    st.markdown("---")
    
    # ë°ì´í„° ë¡œë“œ
    data, filename = load_latest_results()
    
    if not data:
        st.warning("ğŸ“ OCR ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.info("ë¨¼ì € WhatsApp ë¯¸ë””ì–´ OCR ì¶”ì¶œê¸°ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return
    
    st.success(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {filename}")
    
    # ì„±ëŠ¥ ì§€í‘œ
    metrics = create_performance_metrics(data)
    if metrics:
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì´ ë¯¸ë””ì–´", metrics['total_media'])
        with col2:
            st.metric("ì²˜ë¦¬ ì™„ë£Œ", metrics['processed_media'])
        with col3:
            st.metric("ì„±ê³µë¥ ", f"{metrics['success_rate']:.1f}%")
        with col4:
            st.metric("í‰ê·  ì‹ ë¢°ë„", f"{metrics['avg_confidence']:.2f}")
    
    st.markdown("---")
    
    # ì°¨íŠ¸ ì„¹ì…˜
    col1, col2 = st.columns(2)
    
    with col1:
        # OCR ì—”ì§„ ì„±ëŠ¥ ë¹„êµ
        engine_chart = create_engine_comparison_chart(data)
        if engine_chart:
            st.plotly_chart(engine_chart, use_container_width=True)
        else:
            st.info("OCR ì—”ì§„ ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with col2:
        # íŒŒì¼ í˜•ì‹ ë¶„í¬
        file_chart = create_file_type_distribution(data)
        if file_chart:
            st.plotly_chart(file_chart, use_container_width=True)
        else:
            st.info("íŒŒì¼ í˜•ì‹ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì‹ ë¢°ë„ ë¶„í¬
    confidence_chart = create_confidence_distribution(data)
    if confidence_chart:
        st.plotly_chart(confidence_chart, use_container_width=True)
    else:
        st.info("ì‹ ë¢°ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì²˜ë¦¬ ì‹œê°„ ì¶”ì´
    timeline_chart = create_processing_timeline(data)
    if timeline_chart:
        st.plotly_chart(timeline_chart, use_container_width=True)
    else:
        st.info("ì²˜ë¦¬ ì‹œê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë¯¼ê° ì •ë³´ ë¶„ì„
    st.markdown("---")
    st.subheader("ğŸ”’ ë¯¼ê° ì •ë³´ ë¶„ì„")
    
    sensitive_counts, total_texts = analyze_sensitive_info(data)
    if sensitive_counts and total_texts > 0:
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì „í™”ë²ˆí˜¸", sensitive_counts['phone'])
        with col2:
            st.metric("ì´ë©”ì¼", sensitive_counts['email'])
        with col3:
            st.metric("ì£¼ë¯¼ë²ˆí˜¸", sensitive_counts['id_number'])
        with col4:
            st.metric("ì¹´ë“œë²ˆí˜¸", sensitive_counts['card_number'])
        
        st.info(f"ì´ {total_texts}ê°œ í…ìŠ¤íŠ¸ì—ì„œ ë¯¼ê° ì •ë³´ê°€ ìë™ìœ¼ë¡œ ìµëª…í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        st.info("ë¯¼ê° ì •ë³´ê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ìƒì„¸ ê²°ê³¼ í…Œì´ë¸”
    st.markdown("---")
    st.subheader("ğŸ“‹ ìƒì„¸ OCR ê²°ê³¼")
    
    if 'media_results' in data and data['media_results']:
        # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        results_data = []
        for i, result in enumerate(data['media_results']):
            media_info = result.get('media_info', {})
            ocr_result = result.get('ocr_result', {})
            
            results_data.append({
                'ë²ˆí˜¸': i + 1,
                'íŒŒì¼ëª…': result.get('file_path', 'N/A').split('/')[-1],
                'ë¯¸ë””ì–´ íƒ€ì…': media_info.get('type', 'unknown'),
                'OCR ì—”ì§„': ocr_result.get('engine', 'N/A'),
                'ì‹ ë¢°ë„': f"{ocr_result.get('confidence', 0):.2f}",
                'í…ìŠ¤íŠ¸ ê¸¸ì´': len(ocr_result.get('text', '')),
                'ì²˜ë¦¬ ì‹œê°„': result.get('processed_at', 'N/A')
            })
        
        df = pd.DataFrame(results_data)
        st.dataframe(df, use_container_width=True)
        
        # í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
        if st.checkbox("í…ìŠ¤íŠ¸ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°"):
            for i, result in enumerate(data['media_results'][:5]):  # ì²˜ìŒ 5ê°œë§Œ
                ocr_result = result.get('ocr_result', {})
                text = ocr_result.get('text', '')
                
                if text:
                    st.markdown(f"**íŒŒì¼ {i+1}:**")
                    st.text_area(f"í…ìŠ¤íŠ¸ ë‚´ìš©", text[:500] + "..." if len(text) > 500 else text, 
                               height=100, key=f"text_{i}")
    else:
        st.info("OCR ì²˜ë¦¬ëœ ë¯¸ë””ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì‚¬ì´ë“œë°” ì •ë³´
    st.sidebar.title("ğŸ“Š ëŒ€ì‹œë³´ë“œ ì •ë³´")
    st.sidebar.info(f"**ë°ì´í„° íŒŒì¼:** {filename}")
    st.sidebar.info(f"**ì±„íŒ…ë°©:** {data.get('chat_title', 'N/A')}")
    st.sidebar.info(f"**ì²˜ë¦¬ ìƒíƒœ:** {data.get('status', 'N/A')}")
    st.sidebar.info(f"**ì¶”ì¶œ ì‹œê°„:** {data.get('extraction_time', 'N/A')}")
    
    # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
    if st.sidebar.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"):
        st.rerun()

if __name__ == "__main__":
    main() 